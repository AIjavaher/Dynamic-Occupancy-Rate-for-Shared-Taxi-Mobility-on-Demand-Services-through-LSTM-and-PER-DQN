{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NYC taxi data is available to download [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used yellow taxi data for July, August, and September in 2018. All months together (Manhattan request) are approximately 22 million records.\n",
    "Each record represents the one request which includes origin zone, destination zone, date, time, fare,...\n",
    "you can find the description of each field [here](https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf)\n",
    "However, this is the raw data and needs preprocessing. We turned the data into 8 timeslots a day for each zone, representing the number of passengers demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can download the processed data [here]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('july_august_september_taxi_data.csv') # read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a field for holiday data\n",
    "# there are two holidays in July and September\n",
    "data['holy']=0\n",
    "data.at[data['date']=='07/04/2018','holy']=1\n",
    "data.at[data['date']=='09/03/2018','holy']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.sort_values(['date','zone'], ascending=[True,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normal(data,cont_cols):\n",
    "    for col in cont_cols:\n",
    "        mean = data[col].mean()\n",
    "        std = data[col].std()\n",
    "        data[col] = (data[col] - mean) / (1e-7 + std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to predict the number of passengers for each time slot, \n",
    "# we used zone, day, holiday, and the number of passengers in the previous time slot\n",
    "categorical_features = ['zone','day','holy']\n",
    "cont_features = ['num_passenger']\n",
    "output_feature = 'num_passenger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to encode our features. for example, the name of the day turns from 1 to 7\n",
    "label_encoders = {}\n",
    "for cat_col in categorical_features:\n",
    "        label_encoders[cat_col] = LabelEncoder()\n",
    "        data[cat_col] = label_encoders[cat_col].fit_transform(data[cat_col])\n",
    "Normal(data,cont_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# every epoch receives data for a current week and predicts the coming week\n",
    "date = np.unique(data['date'])\n",
    "week=[]\n",
    "for i in range(0,12):\n",
    "    week.append(data[(data['date']>=date[7*i]) & (data['date']<date[7*i+7])][['zone','day','holy','num_passenger',]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set 11 weeks for train and the 1 week for test\n",
    "x_train =[]\n",
    "y_train =[]\n",
    "for j in range(0,11):\n",
    "    for i in range(0,int(len(week[0])/8)):\n",
    "        x=week[j][i*8:i*8+8]\n",
    "        y=week[j+1][i*8:i*8+8][:,3]\n",
    "        x_train.append(x)\n",
    "        y_train.append(y)\n",
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "class MV_LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features, seq_length):\n",
    "        super(MV_LSTM, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.seq_len = seq_length\n",
    "        self.n_hidden = 32  # number of hidden states\n",
    "        self.n_layers = 2  # number of LSTM layers (stacked)\n",
    "\n",
    "        self.l_lstm = torch.nn.LSTM(input_size=n_features,\n",
    "                                    hidden_size=self.n_hidden,\n",
    "                                    num_layers=self.n_layers,\n",
    "                                    batch_first=True)\n",
    "        self.l_linear = torch.nn.Linear(self.n_hidden * self.seq_len, 8)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # even with batch_first = True this remains same as docs\n",
    "        hidden_state = torch.zeros(self.n_layers, batch_size, self.n_hidden)\n",
    "        cell_state = torch.zeros(self.n_layers, batch_size, self.n_hidden)\n",
    "        self.hidden = (hidden_state, cell_state)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        lstm_out, self.hidden = self.l_lstm(x, self.hidden)\n",
    "        x = lstm_out.contiguous().view(batch_size, -1)\n",
    "        return self.l_linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 4 # this is number of parallel inputs\n",
    "n_timesteps = 8 # this is number of timeslots\n",
    "mv_net = MV_LSTM(n_features,n_timesteps)\n",
    "criterion = torch.nn.MSELoss() # loss\n",
    "optimizer = torch.optim.Adam(mv_net.parameters(), lr=1e-1)\n",
    "train_episodes = 500\n",
    "batch_size = len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set the hyperparameters from the experiences were gained from training the other months of data\n",
    "mv_net.train()\n",
    "for t in range(train_episodes):\n",
    "    for b in range(0, len(x_train), batch_size):\n",
    "        inpt = x_train[b:b + batch_size, :, :]\n",
    "        target = y_train[b:b + batch_size]\n",
    "\n",
    "        x_batch = torch.tensor(inpt, dtype=torch.float32)\n",
    "        y_batch = torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "        mv_net.init_hidden(x_batch.size(0))\n",
    "        output = mv_net(x_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if t%50 ==0:\n",
    "        print('step : ', t, 'loss : ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weektest=[]\n",
    "weektest.append(data[(data['date']>=date[77]) & (data['date']<date[84])][['zone','day','holy','num_passenger']].values)\n",
    "weektest.append(data[(data['date']>=date[84]) & (data['date']<=date[90])][['zone','day','holy','num_passenger']].values)\n",
    "x_test =[]\n",
    "y_test =[]\n",
    "for i in range(0,int(len(weektest[0])/8)):\n",
    "    x=weektest[0][i*8:i*8+8]\n",
    "    y=week[1][i*8:i*8+8][:,3]\n",
    "    x_test.append(x)\n",
    "    y_test.append(y)\n",
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_net.eval()\n",
    "with torch.no_grad():\n",
    "    x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "    mv_net.init_hidden(x_test.size(0))\n",
    "    output_t = mv_net(x_test)\n",
    "    loss_test = criterion(output_t, y_test)\n",
    "    print(loss_test.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare with SVR and LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "modesvr_rbf = SVR(kernel='rbf', degree=2, gamma='auto',\n",
    "tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200,\n",
    "verbose=False, max_iter=-1)\n",
    "\n",
    "modesvr_rbf.fit(x_train, y_train)\n",
    "predicted_svr_rbf = modesvr_rbf.predict(x_test)\n",
    "print(\"Model svr_rbf complete\")\n",
    "mse_svr_rbf =  mean_squared_error(predicted_svr_rbf, y_test)\n",
    "print(\"Training data mean squared error: \",mse_svr_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(predicted_svr_rbf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model_lr = linear_model.Lasso(alpha = 0.1)\n",
    "\n",
    "model_lr.fit(x_train, y_train)\n",
    "predicted_LR = model_lr.predict(x_test)\n",
    "print(\"Model lr complete\")\n",
    "\n",
    "mse_lr =  mean_squared_error(predicted_LR, y_test)\n",
    "print(\"Training data mean squared error: \",mse_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(predicted_LR, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
